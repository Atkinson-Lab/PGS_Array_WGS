{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import packages\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import chain\n",
    "import hail as hl\n",
    "from hail.linalg import BlockMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = os.getenv('WORKSPACE_CDR')\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC\n",
    "\n",
    "1. Liftover, key the sumstats by locus  \n",
    "2. Restrict to biallelic variants  \n",
    "3. Negative strand problems  \n",
    "4. Annotate to matrix table, and swap ref:alt if necessary  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liftover, then key the sumstats by locus (done in Step2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rg37 = hl.get_reference('GRCh37')  \n",
    "rg38 = hl.get_reference('GRCh38')   \n",
    "rg37.add_liftover('gs://hail-common/references/grch37_to_grch38.over.chain.gz', rg38)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Hail with default parameters...\n",
      "/opt/conda/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:43: UserWarning:\n",
      "\n",
      "Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buckets`.\n",
      "\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Running on Apache Spark version 3.3.0\n",
      "SparkUI available at http://all-of-us-11150-m.us-central1-c.c.terra-vpc-sc-fd39b54c.internal:38207\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.130.post1-c69cd67afb8b\n",
      "LOGGING: writing to /home/jupyter/workspaces/prswithwgsvsarraydata/hail-20241117-0608-0.2.130.post1-c69cd67afb8b.log\n"
     ]
    }
   ],
   "source": [
    "# 8,996,707 biallelic SNP after QC\n",
    "var_wgs = hl.read_table(f\"{bucket}/WGSData/WGS_Vars_QCed.ht\")\n",
    "var_wgs = var_wgs.key_by(\"locus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantatative traits\n",
    "\n",
    "Use `beta_meta_hq`, `se_meta_hq`, `neglog10_pval_meta_hq`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `var_wgs = var_wgs.repartition(2000)`, var_wgs = var_wgs.checkpoint(ht_filename_check`, overwrite=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2a_Array_SumStats_QC.ipynb performed some preliminary QC for sumstats\n",
    "# The intermediate file is saved as checkpoint\n",
    "# start from the checkpoint files\n",
    "\n",
    "def sumstats_QC_quant(ht_filename_in, ht_filename_check, filename_out, var_wgs):\n",
    "    sumstats = hl.read_table(ht_filename_in)\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    ###################################### Analysis done in Step2a_Array_SumStats_QC.ipynb #######################\n",
    "    # most of the fields are irrelevant for our analysis, drop it first to save computation                      #\n",
    "    # biallelic SNPs                                                                                             #\n",
    "    # check if is_SNP                                                                                            #                                                                                   #\n",
    "    # flip negative strand                                                                                       #\n",
    "    ##############################################################################################################\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    var_wgs = var_wgs.repartition(2000) ###***\n",
    "    \n",
    "    ############## check ref:alt, flip if necessary ############\n",
    "    var_wgs = var_wgs.annotate(**sumstats[var_wgs.locus])\n",
    "    var_wgs = var_wgs.filter((~hl.is_nan(var_wgs.beta_meta_hq)) &\n",
    "                                  (~hl.is_nan(var_wgs.se_meta_hq)) &\n",
    "                                  (~hl.is_nan(var_wgs.neglog10_pval_meta_hq)))\n",
    "    \n",
    "    var_wgs = var_wgs.annotate(beta_meta_fix_ref_alt = hl.case()\n",
    "        .when(((var_wgs.alleles[0] == var_wgs.alleles_fix_neg_strand[0]) & (var_wgs.alleles[1] == var_wgs.alleles_fix_neg_strand[1])), var_wgs.beta_meta_hq) \n",
    "        .when(((var_wgs.alleles[0] == var_wgs.alleles_fix_neg_strand[1]) & (var_wgs.alleles[1] == var_wgs.alleles_fix_neg_strand[0])), -var_wgs.beta_meta_hq)\n",
    "        .default(float('nan')))\n",
    "    \n",
    "    var_wgs = var_wgs.checkpoint(ht_filename_check, overwrite=True)\n",
    "    \n",
    "    sumstats_QCed = var_wgs.select(\n",
    "                        rsid = var_wgs.rsid,\n",
    "                        alleles1_wgs = var_wgs.alleles[0],\n",
    "                        alleles2_wgs = var_wgs.alleles[1],\n",
    "                        alleles1_sumstats_original = var_wgs.ref,\n",
    "                        alleles2_sumstats_original = var_wgs.alt,\n",
    "                        is_negative_strand = var_wgs.is_negative_strand,\n",
    "                        alleles1_sumstats_fixstrand = var_wgs.alleles_fix_neg_strand[0],\n",
    "                        alleles2_sumstats_fixstrand = var_wgs.alleles_fix_neg_strand[1],\n",
    "                        beta_meta = var_wgs.beta_meta_hq,\n",
    "                        beta_meta_fix_ref_alt = var_wgs.beta_meta_fix_ref_alt,\n",
    "                        se_meta = var_wgs.se_meta_hq,\n",
    "                        neglog10_pval_meta = var_wgs.neglog10_pval_meta_hq)\n",
    "    \n",
    "    sumstats_QCed.export(filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height 2024-10-05 02:43:03.270038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred=>(1998 + 2) / 2000]\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.0.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2024-10-05 02:47:47.457 Hail: INFO: wrote table with 8604715 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/continuous-50-both_sexes-irnt_checkpoint2.ht\n",
      "2024-10-05 02:47:57.615 Hail: INFO: merging 2001 files totalling 143.6M... 2000]\n",
      "2024-10-05 02:48:05.689 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_Height_QCed.tsv.bgz\n",
      "  merge time: 8.073s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBP 2024-10-05 02:48:08.169490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 02:51:28.521 Hail: INFO: wrote table with 8503485 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/continuous-DBP-both_sexes-auto_medadj_irnt_checkpoint2.ht\n",
      "2024-10-05 02:51:35.637 Hail: INFO: merging 2001 files totalling 141.9M... 2000]\n",
      "2024-10-05 02:51:42.472 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_DBP_QCed.tsv.bgz\n",
      "  merge time: 6.835s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDL 2024-10-05 02:51:44.884103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 02:54:43.441 Hail: INFO: wrote table with 8484537 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/biomarkers-30760-both_sexes-irnt_checkpoint2.ht\n",
      "2024-10-05 02:54:50.455 Hail: INFO: merging 2001 files totalling 141.8M... 2000]\n",
      "2024-10-05 02:54:56.433 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_HDL_QCed.tsv.bgz\n",
      "  merge time: 5.978s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC 2024-10-05 02:54:58.678035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 02:57:51.717 Hail: INFO: wrote table with 8506131 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/biomarkers-30690-both_sexes-irnt_checkpoint2.ht\n",
      "2024-10-05 02:57:58.627 Hail: INFO: merging 2001 files totalling 142.0M... 2000]\n",
      "2024-10-05 02:58:04.243 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_TC_QCed.tsv.bgz\n",
      "  merge time: 5.615s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBC 2024-10-05 02:58:06.746817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 03:00:51.570 Hail: INFO: wrote table with 8533326 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/continuous-30010-both_sexes-irnt_checkpoint2.ht\n",
      "2024-10-05 03:00:58.495 Hail: INFO: merging 2001 files totalling 142.5M... 2000]\n",
      "2024-10-05 03:01:03.943 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_RBC_QCed.tsv.bgz\n",
      "  merge time: 5.448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leukocyte 2024-10-05 03:01:06.352666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 03:38:33.782 Hail: INFO: wrote table with 8509546 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/continuous-30000-both_sexes-irnt_checkpoint2.ht\n",
      "2024-10-05 03:38:49.985 Hail: INFO: merging 2001 files totalling 141.7M... 2000]\n",
      "2024-10-05 03:38:56.647 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_leukocyte_QCed.tsv.bgz\n",
      "  merge time: 6.662s\n"
     ]
    }
   ],
   "source": [
    "print(\"Height \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/continuous-50-both_sexes-irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/continuous-50-both_sexes-irnt_checkpoint2.ht\", \n",
    "                  f\"{bucket}/Sumstats/WGS_Height_QCed.tsv.bgz\",\n",
    "                  var_wgs)\n",
    "\n",
    "print(\"DBP \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/continuous-DBP-both_sexes-auto_medadj_irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/continuous-DBP-both_sexes-auto_medadj_irnt_checkpoint2.ht\",\n",
    "                  f\"{bucket}/Sumstats/WGS_DBP_QCed.tsv.bgz\",\n",
    "                  var_wgs)\n",
    "\n",
    "print(\"HDL \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/biomarkers-30760-both_sexes-irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/biomarkers-30760-both_sexes-irnt_checkpoint2.ht\",\n",
    "                  f\"{bucket}/Sumstats/WGS_HDL_QCed.tsv.bgz\",\n",
    "                  var_wgs)\n",
    "\n",
    "print(\"TC \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/biomarkers-30690-both_sexes-irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/biomarkers-30690-both_sexes-irnt_checkpoint2.ht\",\n",
    "                  f\"{bucket}/Sumstats/WGS_TC_QCed.tsv.bgz\",\n",
    "                  var_wgs)\n",
    "\n",
    "print(\"RBC \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/continuous-30010-both_sexes-irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/continuous-30010-both_sexes-irnt_checkpoint2.ht\",\n",
    "                  f\"{bucket}/Sumstats/WGS_RBC_QCed.tsv.bgz\",\n",
    "                  var_wgs)\n",
    "\n",
    "print(\"leukocyte \" + str(datetime.now()))\n",
    "sumstats_QC_quant(f\"{bucket}/Sumstats/continuous-30000-both_sexes-irnt_checkpoint.ht\",\n",
    "                  f\"{bucket}/Sumstats/continuous-30000-both_sexes-irnt_checkpoint2.ht\",\n",
    "                  f\"{bucket}/Sumstats/WGS_leukocyte_QCed.tsv.bgz\",\n",
    "                  var_wgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary traits\n",
    "\n",
    "Use `beta_meta`, `se_meta`, `neglog10_pval_meta`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `var_wgs = var_wgs.repartition(2000)`, var_wgs = var_wgs.checkpoint(ht_filename_check`, overwrite=True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2a_Array_SumStats_QC.ipynb performed some preliminary QC for sumstats\n",
    "# The intermediate file is saved as checkpoint\n",
    "# start from the checkpoint files\n",
    "\n",
    "def sumstats_QC_binary(ht_filename_in, ht_filename_check, filename_out, var_wgs):\n",
    "    sumstats = hl.read_table(ht_filename_in)\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    ###################################### Analysis done in Step2a_Array_SumStats_QC.ipynb #######################\n",
    "    # most of the fields are irrelevant for our analysis, drop it first to save computation                      #\n",
    "    # biallelic SNPs                                                                                             #\n",
    "    # check if is_SNP                                                                                            #                                                                                   #\n",
    "    # flip negative strand                                                                                       #\n",
    "    ##############################################################################################################\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    var_wgs = var_wgs.repartition(2000) ###***\n",
    "        \n",
    "    ############## check ref:alt, flip if necessary ############\n",
    "    var_wgs = var_wgs.annotate(**sumstats[var_wgs.locus])\n",
    "    var_wgs = var_wgs.filter((~hl.is_nan(var_wgs.beta_meta)) &\n",
    "                                  (~hl.is_nan(var_wgs.se_meta)) &\n",
    "                                  (~hl.is_nan(var_wgs.neglog10_pval_meta)))\n",
    "    \n",
    "    var_wgs = var_wgs.annotate(beta_meta_fix_ref_alt = hl.case()\n",
    "        .when(((var_wgs.alleles[0] == var_wgs.alleles_fix_neg_strand[0]) & (var_wgs.alleles[1] == var_wgs.alleles_fix_neg_strand[1])), var_wgs.beta_meta) \n",
    "        .when(((var_wgs.alleles[0] == var_wgs.alleles_fix_neg_strand[1]) & (var_wgs.alleles[1] == var_wgs.alleles_fix_neg_strand[0])), -var_wgs.beta_meta)\n",
    "        .default(float('nan')))\n",
    "    \n",
    "    var_wgs = var_wgs.checkpoint(ht_filename_check, overwrite=True)\n",
    "    \n",
    "    sumstats_QCed = var_wgs.select(\n",
    "                        rsid = var_wgs.rsid,\n",
    "                        alleles1_wgs = var_wgs.alleles[0],\n",
    "                        alleles2_wgs = var_wgs.alleles[1],\n",
    "                        alleles1_sumstats_original = var_wgs.ref,\n",
    "                        alleles2_sumstats_original = var_wgs.alt,\n",
    "                        is_negative_strand = var_wgs.is_negative_strand,\n",
    "                        alleles1_sumstats_fixstrand = var_wgs.alleles_fix_neg_strand[0],\n",
    "                        alleles2_sumstats_fixstrand = var_wgs.alleles_fix_neg_strand[1],\n",
    "                        beta_meta = var_wgs.beta_meta,\n",
    "                        beta_meta_fix_ref_alt = var_wgs.beta_meta_fix_ref_alt,\n",
    "                        se_meta = var_wgs.se_meta,\n",
    "                        neglog10_pval_meta = var_wgs.neglog10_pval_meta)\n",
    "    \n",
    "    sumstats_QCed.export(filename_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T2D 2024-10-05 04:39:35.791189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred=>(1995 + 5) / 2000]\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.0.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2024-10-05 04:43:46.343 Hail: INFO: wrote table with 8604426 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/phecode-250.2-both_sexes_checkpoint2.ht\n",
      "2024-10-05 04:43:55.818 Hail: INFO: merging 2001 files totalling 142.6M... 2000]\n",
      "2024-10-05 04:44:01.980 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_T2D_QCed.tsv.bgz\n",
      "  merge time: 6.160s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma 2024-10-05 04:44:04.744452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 04:50:00.856 Hail: INFO: wrote table with 8605299 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/phecode-495-both_sexes_checkpoint2.ht\n",
      "2024-10-05 04:50:21.397 Hail: INFO: merging 2001 files totalling 143.7M... 2000]\n",
      "2024-10-05 04:50:26.750 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_Asthma_QCed.tsv.bgz\n",
      "  merge time: 5.353s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast_Cancer 2024-10-05 04:50:29.165377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:============>                                    (36764 + 0) / 140126]\r"
     ]
    }
   ],
   "source": [
    "print(\"T2D \" + str(datetime.now()))\n",
    "sumstats_QC_binary(f\"{bucket}/Sumstats/phecode-250.2-both_sexes_checkpoint.ht\",\n",
    "                   f\"{bucket}/Sumstats/phecode-250.2-both_sexes_checkpoint2.ht\",\n",
    "                   f\"{bucket}/Sumstats/WGS_T2D_QCed.tsv.bgz\",\n",
    "                   var_wgs)\n",
    "\n",
    "print(\"Asthma \" + str(datetime.now()))\n",
    "sumstats_QC_binary(f\"{bucket}/Sumstats/phecode-495-both_sexes_checkpoint.ht\",\n",
    "                   f\"{bucket}/Sumstats/phecode-495-both_sexes_checkpoint2.ht\",\n",
    "                   f\"{bucket}/Sumstats/WGS_Asthma_QCed.tsv.bgz\",\n",
    "                   var_wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast_Cancer 2024-10-05 05:06:25.031190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred=>(1999 + 1) / 2000]\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.0.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2024-10-05 05:10:17.745 Hail: INFO: wrote table with 8601970 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/phecode-174.1-females_checkpoint2.ht\n",
      "2024-10-05 05:10:27.145 Hail: INFO: merging 2001 files totalling 142.0M... 2000]\n",
      "2024-10-05 05:10:33.362 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_Breast_Cancer_QCed.tsv.bgz\n",
      "  merge time: 6.216s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorectal_Cancer 2024-10-05 05:10:35.998043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======>                                          (19831 + 0) / 140126]\r"
     ]
    }
   ],
   "source": [
    "print(\"Breast_Cancer \" + str(datetime.now()))\n",
    "sumstats_QC_binary(f\"{bucket}/Sumstats/phecode-174.1-females_checkpoint.ht\", \n",
    "                   f\"{bucket}/Sumstats/phecode-174.1-females_checkpoint2.ht\",\n",
    "                   f\"{bucket}/Sumstats/WGS_Breast_Cancer_QCed.tsv.bgz\",\n",
    "                   var_wgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colorectal_Cancer 2024-10-05 05:27:12.723094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred=>(1997 + 3) / 2000]\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.0.jar) to field java.util.concurrent.locks.ReentrantReadWriteLock.readerLock\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "2024-10-05 05:37:42.557 Hail: INFO: wrote table with 8537841 rows in 2000 partitions to gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/phecode-153-both_sexes_checkpoint2.ht\n",
      "2024-10-05 05:37:59.045 Hail: INFO: merging 2001 files totalling 141.2M... 2000]\n",
      "2024-10-05 05:38:04.686 Hail: INFO: while writing:\n",
      "    gs://fc-secure-9afe7562-2fad-4781-ab60-03528a626c19/Sumstats/WGS_Colorectal_Cancer_QCed.tsv.bgz\n",
      "  merge time: 5.640s\n"
     ]
    }
   ],
   "source": [
    "print(\"Colorectal_Cancer \" + str(datetime.now()))\n",
    "sumstats_QC_binary(f\"{bucket}/Sumstats/phecode-153-both_sexes_checkpoint.ht\",\n",
    "                   f\"{bucket}/Sumstats/phecode-153-both_sexes_checkpoint2.ht\",\n",
    "                   f\"{bucket}/Sumstats/WGS_Colorectal_Cancer_QCed.tsv.bgz\",\n",
    "                   var_wgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
